# MÃ³dulo Balancer - Data Balancer Distribuido

## ğŸ“‹ DescripciÃ³n

Sistema de balanceo de carga distribuido para DistriSearch. Gestiona el **Ã­ndice global** de tÃ©rminos y el **registro de nodos**.

## ğŸ“ Estructura

```
balancer/
â”œâ”€â”€ __init__.py              # Exports pÃºblicos
â”œâ”€â”€ global_index.py          # Ãndice global: tÃ©rmino â†’ nodos
â”œâ”€â”€ node_registry.py         # Registro de nodos activos
â”œâ”€â”€ balancer_core.py         # DataBalancer principal
â””â”€â”€ balancer_snapshots.py    # GestiÃ³n de snapshots
```

## ğŸ¯ Componentes

### 1. `global_index.py`
**Ãndice global distribuido:**
- Estructura: `tÃ©rmino â†’ {node_ids}`
- `add_term()`: Registrar tÃ©rmino en nodo
- `get_nodes_for_term()`: Localizar nodos con tÃ©rmino
- `get_nodes_for_terms()`: Localizar nodos (OR)
- `remove_node()`: Limpiar nodo completo

### 2. `node_registry.py`
**Registro de nodos:**
- `NodeMetadata`: Metadata de cada nodo
  - `node_id`, `address`, `port`
  - `last_heartbeat`, `document_count`, `term_count`
- `NodeRegistry`: Gestor de nodos
  - `register()`, `unregister()`
  - `heartbeat()`: Actualizar actividad
  - `get_active_nodes()`: Nodos vivos
  - `clean_dead_nodes()`: Eliminar inactivos

### 3. `balancer_core.py`
**DataBalancer principal:**
- Orquestador que combina GlobalIndex + NodeRegistry
- `locate_terms()`: Â¿DÃ³nde estÃ¡n estos tÃ©rminos?
- `update_node_index()`: Actualizar Ã­ndice de nodo
- `register_node()` / `unregister_node()`
- `get_stats()`: EstadÃ­sticas del sistema

### 4. `balancer_snapshots.py`
**GestiÃ³n de snapshots:**
- `save_snapshot()`: Guardar estado completo
- `load_snapshot()`: Restaurar desde snapshot
- `list_snapshots()`: Listar backups

## ğŸ”§ Uso

### Inicializar Data Balancer

```python
from balancer import DataBalancer
from storage.persistence import PersistenceManager

# Crear balancer
balancer = DataBalancer(node_id=100)

# Registrar nodos
balancer.register_node(1, "192.168.1.10", 8001)
balancer.register_node(2, "192.168.1.11", 8002)
balancer.register_node(3, "192.168.1.12", 8003)
```

### Actualizar Ãndice Global

```python
# Nodo 1 reporta sus tÃ©rminos
balancer.update_node_index(
    node_id=1,
    terms=["distributed", "consensus", "raft"]
)

# Nodo 2 reporta sus tÃ©rminos
balancer.update_node_index(
    node_id=2,
    terms=["hypercube", "routing", "network"]
)
```

### Localizar TÃ©rminos

```python
# Â¿QuÃ© nodos tienen "consensus" o "raft"?
node_ids = balancer.locate_terms(["consensus", "raft"])
# {1}

# Â¿QuÃ© nodos tienen "hypercube"?
node_ids = balancer.locate_term("hypercube")
# {2}
```

### Heartbeats

```python
# Nodo envÃ­a heartbeat con stats
balancer.heartbeat(
    node_id=1,
    doc_count=150,
    term_count=500
)

# Verificar nodos activos
active = balancer.get_active_nodes()
# {1, 2, 3}
```

### Snapshots

```python
from balancer import SnapshotManager

# Crear gestor
persistence = PersistenceManager("data/balancer_0")
snapshots = SnapshotManager(balancer, persistence)

# Guardar snapshot
snapshots.save_snapshot("backup_latest")

# Restaurar
snapshots.load_snapshot("backup_latest")

# Listar backups
all_snapshots = snapshots.list_snapshots()
```

## ğŸ“Š Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       DataBalancer (LÃ­der)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GlobalIndex    â”‚  NodeRegistry     â”‚
â”‚  tÃ©rminoâ†’nodos  â”‚  nodos activos    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–²                 â–²
          â”‚ update_index    â”‚ heartbeat
          â”‚                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           â”‚                â”‚          â”‚
  Node 1      Node 2          Node 3     Node 4
  (doc1-3)    (doc4-6)        (doc7-9)   (doc10-12)
```

## ğŸ” Flujo de BÃºsqueda

1. **Cliente** envÃ­a query a cualquier nodo
2. **Nodo** tokeniza query â†’ tÃ©rminos
3. **Nodo** contacta DataBalancer: `locate_terms(tÃ©rminos)`
4. **DataBalancer** retorna `{node_ids}` que tienen tÃ©rminos
5. **Nodo** contacta nodos relevantes en paralelo
6. **Nodo** agrega resultados y rankea (TF-IDF)
7. **Nodo** retorna top-K resultados a cliente

## ğŸ“ˆ EstadÃ­sticas

```python
stats = balancer.get_stats()
# {
#   "node_id": 100,
#   "global_index": {
#     "terms": 1500,
#     "nodes": 8
#   },
#   "node_registry": {
#     "total_nodes": 8,
#     "active_nodes": 7,
#     "total_documents": 1200,
#     "total_terms": 5000
#   }
# }
```

## ğŸ›ï¸ ConfiguraciÃ³n de Heartbeat

```python
HEARTBEAT_TIMEOUT = 30.0  # segundos sin heartbeat â†’ nodo muerto

# Limpiar nodos muertos periÃ³dicamente
removed = balancer.node_registry.clean_dead_nodes(timeout=30.0)
print(f"Eliminados {removed} nodos inactivos")
```

## ğŸš€ Escalabilidad

### Problema Original (Bottleneck)
âŒ **Un Ãºnico DataBalancer** â†’ cuello de botella M/M/1

### SoluciÃ³n Propuesta
âœ… **MÃºltiples DataBalancers** (uno por shard):
- Sharding por consistant hashing
- Cada shard tiene su DataBalancer
- Reducir carga de N/16 (para 16 shards)

```python
# En lugar de UN balancer global
balancer_global = DataBalancer()

# Usar 16 balancers (uno por shard)
balancers = [DataBalancer(i) for i in range(16)]

# Localizar tÃ©rmino â†’ determinar shard â†’ consultar balancer[shard]
shard = hash(term) % 16
nodes = balancers[shard].locate_term(term)
```

## ğŸ“Š Persistencia

```python
# Guardar estado completo
data = balancer.to_dict()
persistence.save_json("global_index.json", data["global_index"])
persistence.save_json("nodes_metadata.json", data["nodes_metadata"])

# Cargar estado
global_data = persistence.load_json("global_index.json")
nodes_data = persistence.load_json("nodes_metadata.json")

balancer.from_dict({
    "global_index": global_data,
    "nodes_metadata": nodes_data
})
```

## âœ… GarantÃ­as

1. **Consistencia eventual**: Ãndice global se actualiza por heartbeats
2. **Fault tolerance**: Si un nodo muere, se limpia en 30s
3. **Idempotencia**: Actualizar mismo tÃ©rmino varias veces es seguro

## ğŸ”„ IntegraciÃ³n con Consensus

Para **alta disponibilidad**, el DataBalancer puede usar Raft:

```python
# DataBalancer lÃ­der replica su estado
if raft.is_leader():
    await raft.replicate_command({
        "type": "update_index",
        "node_id": 1,
        "terms": ["consensus", "raft"]
    })
```

## ğŸš§ Mejoras Futuras

- [ ] Sharding del Ã­ndice global (16 shards)
- [ ] ReplicaciÃ³n del DataBalancer (k=3)
- [ ] CachÃ© de locate_terms() (LRU)
- [ ] CompresiÃ³n de snapshots
- [ ] MÃ©tricas Prometheus
