<p align="center">
  <img src="DistriSearch/assets/logo.png" alt="DistriSearch Logo" width="200"/>
</p>

# üîç DistriSearch - Sistema de B√∫squeda Distribuida Master-Slave

Sistema de b√∫squeda distribuida de archivos con arquitectura **Master-Slave din√°mico**, localizaci√≥n sem√°ntica, replicaci√≥n por afinidad y tolerancia a fallos.

![Version](https://img.shields.io/badge/version-3.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)
![MongoDB](https://img.shields.io/badge/mongodb-6.0-brightgreen.svg)
![License](https://img.shields.io/badge/license-MIT-orange.svg)

---

## üìë Tabla de Contenidos

- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Tolerancia a Fallos](#-tolerancia-a-fallos)
- [Coordinaci√≥n Distribuida](#-coordinaci√≥n-distribuida)
- [Sistema de Nombres](#-sistema-de-nombres)
- [Replicaci√≥n y Consistencia](#-replicaci√≥n-y-consistencia)
- [Requisitos](#-requisitos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Configuraci√≥n](#-configuraci√≥n)
- [Uso](#-uso)
- [API Endpoints](#-api-endpoints)
- [Testing](#-testing)
- [Documentaci√≥n](#-documentaci√≥n)

---

## ‚ú® Caracter√≠sticas Principales

### üéØ Funcionalidades Core

| Caracter√≠stica | Descripci√≥n | Estado |
|----------------|-------------|--------|
| **B√∫squeda Sem√°ntica** | Embeddings con sentence-transformers (384 dims) | ‚úÖ Completo |
| **Arquitectura Master-Slave** | L√≠der din√°mico con elecci√≥n Bully | ‚úÖ Completo |
| **Localizaci√≥n Sem√°ntica** | √çndice vectorial distribuido por afinidad | ‚úÖ Completo |
| **Replicaci√≥n Din√°mica** | Factor configurable con afinidad sem√°ntica | ‚úÖ Completo |
| **Tolerancia a Fallos** | Heartbeat UDP + elecci√≥n autom√°tica | ‚úÖ Completo |
| **Naming Jer√°rquico** | Rutas estilo Unix con aliases | ‚úÖ Completo |
| **Descubrimiento Autom√°tico** | Multicast UDP para detecci√≥n de nodos | ‚úÖ Completo |
| **Consistencia Eventual** | Replicaci√≥n as√≠ncrona coordinada | ‚úÖ Completo |

---

## üèóÔ∏è Arquitectura del Sistema

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (Streamlit)                      ‚îÇ
‚îÇ  ‚Ä¢ Interfaz de usuario                                      ‚îÇ
‚îÇ  ‚Ä¢ B√∫squeda interactiva                                     ‚îÇ
‚îÇ  ‚Ä¢ Gesti√≥n de nodos                                         ‚îÇ
‚îÇ  ‚Ä¢ Visualizaci√≥n de cluster                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP/REST
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BACKEND (FastAPI)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ API Layer (routes/)                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /search    - B√∫squeda sem√°ntica                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /register  - Gesti√≥n de nodos y archivos          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /download  - Descarga de archivos                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /cluster   - Estado del cluster                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /naming    - Sistema de nombres jer√°rquico        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ /health    - Health checks                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Services Layer (services/)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DynamicReplicationService                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ NodeService                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ClusterInitializer                                ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CLUSTER MODULE                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ HeartbeatService   - Monitoreo UDP (puerto 5000)  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ BullyElection      - Elecci√≥n l√≠der (puerto 5001) ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ MulticastDiscovery - Descubrimiento autom√°tico    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ HierarchicalNaming - Sistema de nombres           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ IPCache            - Cache LRU de nodos           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MASTER MODULE                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ EmbeddingService        - Generaci√≥n embeddings   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ LocationIndex           - √çndice vectorial        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ QueryRouter             - Enrutamiento consultas  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ReplicationCoordinator  - Coordinador r√©plicas    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ LoadBalancer            - Balanceo de carga       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CORE MODULE                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ models.py  - Modelos unificados (Enums, Pydantic) ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ config.py  - Configuraci√≥n centralizada           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MONGODB                                   ‚îÇ
‚îÇ  Collections: files, nodes, file_contents, replications     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Estructura del Proyecto

```
DistriSearch/
‚îú‚îÄ‚îÄ core/                    # M√≥dulo central
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Modelos unificados (Enums, Dataclasses, Pydantic)
‚îÇ   ‚îî‚îÄ‚îÄ config.py           # Configuraci√≥n centralizada
‚îÇ
‚îú‚îÄ‚îÄ cluster/                 # M√≥dulo de cluster (comunicaci√≥n entre nodos)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ heartbeat.py        # Servicio de heartbeat UDP
‚îÇ   ‚îú‚îÄ‚îÄ election.py         # Algoritmo Bully para elecci√≥n de l√≠der
‚îÇ   ‚îú‚îÄ‚îÄ discovery.py        # Descubrimiento multicast UDP
‚îÇ   ‚îî‚îÄ‚îÄ naming/             # Sistema de nombres
‚îÇ       ‚îú‚îÄ‚îÄ hierarchical.py # Namespace jer√°rquico
‚îÇ       ‚îî‚îÄ‚îÄ ip_cache.py     # Cache LRU de IPs
‚îÇ
‚îú‚îÄ‚îÄ master/                  # M√≥dulo Master (localizaci√≥n sem√°ntica)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py    # Generaci√≥n de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ location_index.py       # √çndice vectorial distribuido
‚îÇ   ‚îú‚îÄ‚îÄ query_router.py         # Enrutamiento de consultas
‚îÇ   ‚îú‚îÄ‚îÄ replication_coordinator.py  # Coordinador de r√©plicas
‚îÇ   ‚îî‚îÄ‚îÄ load_balancer.py        # Balanceo de carga
‚îÇ
‚îú‚îÄ‚îÄ backend/                 # API REST (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Punto de entrada
‚îÇ   ‚îú‚îÄ‚îÄ database.py         # Conexi√≥n MongoDB
‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Re-exports de core/models.py
‚îÇ   ‚îú‚îÄ‚îÄ routes/             # Endpoints REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ register.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ download.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cluster.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ naming.py
‚îÇ   ‚îî‚îÄ‚îÄ services/           # Servicios de negocio
‚îÇ       ‚îú‚îÄ‚îÄ node_service.py
‚îÇ       ‚îú‚îÄ‚îÄ replication_service.py
‚îÇ       ‚îî‚îÄ‚îÄ dynamic_replication.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/                # UI (Streamlit)
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îÇ
‚îú‚îÄ‚îÄ deploy/                  # Configuraci√≥n Docker
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml          # Desarrollo local
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.cluster.yml  # Cluster multi-nodo
‚îÇ
‚îú‚îÄ‚îÄ tests/                   # Tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ
‚îî‚îÄ‚îÄ docs/                    # Documentaci√≥n MkDocs
```

---

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AGENTES (Nodos P2P)                       ‚îÇ
‚îÇ  ‚Ä¢ Registro autom√°tico                                      ‚îÇ
‚îÇ  ‚Ä¢ Escaneo de archivos local                                ‚îÇ
‚îÇ  ‚Ä¢ Servidor de archivos HTTP                                ‚îÇ
‚îÇ  ‚Ä¢ Heartbeat peri√≥dico                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ°Ô∏è Tolerancia a Fallos

### Arquitectura de Alta Disponibilidad

DistriSearch implementa un sistema **Master-Slave din√°mico** donde cualquier nodo puede convertirse en Master mediante el algoritmo de elecci√≥n Bully.

### üîÑ Mecanismos de Tolerancia

| Mecanismo | Implementaci√≥n | M√≥dulo |
|-----------|----------------|--------|
| **Heartbeat UDP** | PING/PONG cada 5s, timeout 15s | `cluster/heartbeat.py` |
| **Elecci√≥n Bully** | Nodo con mayor ID gana | `cluster/election.py` |
| **Replicaci√≥n** | Factor k=3 por defecto | `backend/services/dynamic_replication.py` |
| **Descubrimiento** | Multicast UDP 239.255.0.1:5353 | `cluster/discovery.py` |

### üì° Protocolo de Heartbeat

```
   Slave A                     Slave B                     Master
      ‚îÇ                          ‚îÇ                           ‚îÇ
      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                           ‚îÇ
      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PONG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫                           ‚îÇ
      ‚îÇ                          ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
      ‚îÇ                          ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PONG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫
      ‚îÇ                          ‚îÇ                           ‚îÇ
      ‚îÇ    [Master timeout - 15s sin respuesta]              ‚îÇ
      ‚îÇ                          ‚îÇ                           X
      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ELECTION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                           
      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ELECTION_OK ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫                           
      ‚îÇ                          ‚îÇ‚îÄ‚îÄ‚îÄ (Mayor ID, se proclama)
      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ COORDINATOR ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                           
      ‚îÇ                          ‚îÇ [Nuevo Master]            
```

### üéØ Proceso de Elecci√≥n (Algoritmo Bully)

1. **Detecci√≥n**: Heartbeat timeout detecta Master ca√≠do
2. **Inicio**: Nodo env√≠a ELECTION a todos con ID mayor
3. **Respuesta**: Nodos con ID mayor responden ELECTION_OK
4. **Proclamaci√≥n**: Si no hay respuesta, se proclama COORDINATOR
5. **Notificaci√≥n**: Nuevo Master env√≠a COORDINATOR a todos

---

## üéõÔ∏è Coordinaci√≥n Distribuida

### Elecci√≥n de L√≠der (Algoritmo Bully)

**Algoritmo:** Bully Election - El nodo con mayor ID siempre gana

**Tipos de Mensajes:**

| Mensaje | Descripci√≥n |
|---------|-------------|
| `ELECTION` | Solicitud de elecci√≥n enviada a nodos con ID mayor |
| `ELECTION_OK` | Respuesta indicando que el nodo participar√° |
| `COORDINATOR` | Anuncio del nuevo l√≠der a todos los nodos |

**C√≥digo de ejemplo:**

```python
from cluster import BullyElection, HeartbeatService

# Crear servicios
heartbeat = HeartbeatService(
    node_id="node_1",
    port=5000,
    on_master_down=lambda: election.start_election()
)

election = BullyElection(
    node_id="node_1", 
    port=5001,
    on_become_master=lambda: print("¬°Soy el nuevo Master!"),
    on_new_master=lambda master_id: print(f"Nuevo master: {master_id}")
)

# A√±adir peers
election.add_peer("node_2", "192.168.1.2", 5001, can_be_master=True)
election.add_peer("node_3", "192.168.1.3", 5001, can_be_master=True)

# Iniciar
await heartbeat.start()
await election.start()
```

### üîÑ Configuraci√≥n de Cluster

Variables de entorno:

```bash
# Identificaci√≥n
NODE_ID=node_1
NODE_ROLE=slave          # slave | master (inicial)
MASTER_CANDIDATE=true    # Puede ser elegido Master

# Comunicaci√≥n
HEARTBEAT_PORT=5000      # Puerto UDP para heartbeats
ELECTION_PORT=5001       # Puerto UDP para elecci√≥n
HEARTBEAT_INTERVAL=5     # Segundos entre PINGs
HEARTBEAT_TIMEOUT=15     # Segundos para detectar falla

# Peers
CLUSTER_PEERS=node_2:192.168.1.2:8000:5000:5001,node_3:192.168.1.3:8000:5000:5001

# Endpoints
POST /coordination/election/start  # Iniciar elecci√≥n
GET /coordination/status           # Estado actual
```

**Ventajas:**
- ‚úÖ Sin punto central de falla
- ‚úÖ Resistente a ataques Sybil
- ‚úÖ Elecci√≥n justa basada en capacidad computacional

### Exclusi√≥n Mutua Distribuida

**Algoritmo:** Ricart-Agrawala modificado

**Caracter√≠sticas:**
- Relojes l√≥gicos de Lamport para ordenamiento
- Confirmaci√≥n de todos los nodos antes de acceso
- Diferimiento de replies para evitar deadlock

```python
# Adquirir bloqueo
POST /coordination/lock/acquire
{
  "resource_id": "file_123"
}

# Liberar bloqueo
POST /coordination/lock/release
{
  "resource_id": "file_123"
}
```

**Casos de uso:**
- Escrituras concurrentes en el mismo archivo
- Actualizaci√≥n de metadata compartida
- Operaciones de checkpoint coordinado

### Sincronizaci√≥n con Relojes de Lamport

```python
class LamportClock:
    def increment(self) -> int:
        """Incrementar en evento local"""
        self.counter += 1
        return self.counter
    
    def update(self, received_time: int) -> int:
        """Actualizar al recibir mensaje"""
        self.counter = max(self.counter, received_time) + 1
        return self.counter
```

**Propiedades garantizadas:**
- Si evento `a` ocurre antes que `b`, entonces `L(a) < L(b)`
- Orden total de eventos en el sistema
- Resoluci√≥n de conflictos determinista

---

## üìõ Sistema de Nombres

### Naming Jer√°rquico

**Inspiraci√≥n:** Unix Filesystem + DNS

**Estructura:**

```
/                               # Ra√≠z
‚îú‚îÄ‚îÄ proyectos/                  # Directorio
‚îÇ   ‚îú‚îÄ‚îÄ distrisearch/          
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ readme.md      # Archivo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ otro_proyecto/
‚îî‚îÄ‚îÄ compartido/
    ‚îî‚îÄ‚îÄ datos.csv
```

**Operaciones:**

```python
# Registrar archivo en path
POST /naming/register_path
{
  "path": "/proyectos/distrisearch/docs/readme.md",
  "file_id": "abc123",
  "metadata": {"size": 1024, "type": "document"}
}

# Resolver path
GET /naming/resolve?path=/proyectos/distrisearch/docs/readme.md

# Listar directorio
GET /naming/list?path=/proyectos/distrisearch

# Crear alias (symbolic link)
POST /naming/alias
{
  "alias_path": "/docs/manual.pdf",
  "real_path": "/proyectos/distrisearch/docs/manual.pdf"
}

# B√∫squeda con wildcards
GET /naming/search?pattern=/proyectos/**/readme.md
```

**Caracter√≠sticas:**
- ‚úÖ Navegaci√≥n estilo Unix
- ‚úÖ Aliases (symbolic links)
- ‚úÖ B√∫squeda por patr√≥n (wildcards)
- ‚úÖ Persistencia en MongoDB
- ‚úÖ Cache en memoria para performance

### Descubrimiento de Nodos (Multicast)

**Protocolo:** UDP Multicast (similar a mDNS)

**Configuraci√≥n:**

```bash
MULTICAST_GROUP=239.255.0.1
MULTICAST_PORT=5353
DISCOVERY_INTERVAL=30  # segundos
```

**Mensajes:**

```json
// Anuncio de nodo
{
  "type": "node_announce",
  "node_id": "agent_01",
  "ip_address": "192.168.1.100",
  "port": 8080,
  "timestamp": "2024-01-15T10:00:00Z"
}

// Query de nodos
{
  "type": "node_query",
  "requesting_node": "central"
}

// Respuesta
{
  "type": "node_response",
  "node_id": "agent_02",
  "ip_address": "192.168.1.101",
  "port": 8081
}
```

**Ventajas:**
- ‚úÖ Zero-configuration networking
- ‚úÖ Descubrimiento autom√°tico en LAN
- ‚úÖ Detecci√≥n de nodos ca√≠dos (timeout 3x interval)
- ‚úÖ Bajo overhead de red

### IP Cache

**Prop√≥sito:** Reducir latencia de consultas a MongoDB

```python
class IPCache:
    def __init__(self):
        self.cache: Dict[str, Dict] = {}
        self.ttl = 300  # 5 minutos
    
    def get(self, node_id: str) -> Optional[Dict]:
        """Obtener con validaci√≥n de TTL"""
        if node_id in self.cache:
            cached = self.cache[node_id]
            if (datetime.now() - cached['cached_at']).seconds < self.ttl:
                return cached['data']
        return None
```

**Estrategia:**
- Cache miss ‚Üí Query a MongoDB ‚Üí Cache en memoria
- Invalidaci√≥n en actualizaci√≥n de nodo
- TTL de 5 minutos para evitar datos obsoletos

---

## üîÑ Replicaci√≥n y Consistencia

### Modelo de Consistencia

**Teorema CAP:** DistriSearch elige **CP** (Consistencia + Tolerancia a Particiones)

| Propiedad | Elecci√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| **C**onsistencia | ‚úÖ **Eventual** | Sincronizaci√≥n cada 60s |
| **A**vailability | ‚ö†Ô∏è Parcial | Requiere mayor√≠a online |
| **P**artition Tolerance | ‚úÖ Completo | Sigue operando con particiones |

### Protocolo de Replicaci√≥n

**Estrategia:** Escritura Local + Propagaci√≥n As√≠ncrona

**Pasos:**

1. **Escritura local**: Usuario sube archivo al nodo m√°s cercano
2. **Registro en DB**: MongoDB registra metadata
3. **Selecci√≥n de r√©plicas**: Hash consistente selecciona k=3 nodos
4. **Replicaci√≥n paralela**: Transferencia HTTP a nodos destino
5. **Confirmaci√≥n**: Actualizaci√≥n de estado en MongoDB

**C√≥digo:**

```python
async def replicate_file(self, file_meta: Dict, source_node_id: str) -> Dict:
    """Replica archivo a k nodos"""
    file_id = file_meta['file_id']
    
    # Seleccionar nodos con hash consistente
    target_nodes = self.get_replication_nodes(file_id, exclude_nodes={source_node_id})
    
    # Replicar en paralelo
    tasks = [
        self._replicate_to_node(file_meta, source_node_id, node)
        for node in target_nodes
    ]
    
    responses = await asyncio.gather(*tasks, return_exceptions=True)
    
    return {
        "file_id": file_id,
        "replicated_to": [r['node_id'] for r in responses if r['status'] == 'success'],
        "failed": [r['node_id'] for r in responses if r['status'] == 'failed']
    }
```

### Sincronizaci√≥n de Consistencia Eventual

**Loop de sincronizaci√≥n:**

```python
async def synchronize_eventual_consistency(self):
    """Ejecutado cada 60 segundos"""
    # 1. Detectar archivos con m√∫ltiples versiones
    pipeline = [
        {"$group": {
            "_id": "$file_id",
            "versions": {"$push": {
                "node_id": "$node_id",
                "last_updated": "$last_updated",
                "content_hash": "$content_hash"
            }}
        }}
    ]
    
    files_versions = list(self.db.files.aggregate(pipeline))
    
    # 2. Resolver conflictos (last-write-wins)
    for file_group in files_versions:
        versions = file_group['versions']
        
        if len(versions) > 1:
            canonical = max(versions, key=lambda v: v['last_updated'])
            
            # 3. Propagar versi√≥n can√≥nica
            await self._propagate_canonical_version(
                file_group['_id'],
                canonical,
                versions
            )
```

### Resoluci√≥n de Conflictos

**Estrategias soportadas:**

| Estrategia | Descripci√≥n | Configuraci√≥n |
|------------|-------------|---------------|
| **last-write-wins** | √öltima escritura prevalece | `CONFLICT_RESOLUTION=last_write_wins` |
| **first-write-wins** | Primera escritura prevalece | `CONFLICT_RESOLUTION=first_write_wins` |
| **manual** | Requiere intervenci√≥n humana | `CONFLICT_RESOLUTION=manual` |

**Detecci√≥n de conflictos:**

```python
# Archivo con mismo file_id pero diferente content_hash
conflict = self.db.files.aggregate([
    {"$group": {
        "_id": "$file_id",
        "hashes": {"$addToSet": "$content_hash"},
        "count": {"$sum": 1}
    }},
    {"$match": {"count": {"$gt": 1}}}
])
```

---

## üìã Requisitos

### Software

| Componente | Versi√≥n M√≠nima | Recomendada |
|------------|----------------|-------------|
| **Python** | 3.10 | 3.12 |
| **MongoDB** | 5.0 | 6.0 |
| **Docker** | 20.10 | 24.0 |
| **Docker Compose** | 2.0 | 2.24 |

### Hardware

**Backend:**
- CPU: 2 cores
- RAM: 2 GB
- Disco: 10 GB

**Agente:**
- CPU: 1 core
- RAM: 512 MB
- Disco: 5 GB

**Producci√≥n (recomendado):**
- CPU: 4 cores
- RAM: 8 GB
- Disco: 50 GB SSD

---

## üöÄ Instalaci√≥n

### Opci√≥n 1: Docker Compose (Recomendado)

```bash
# 1. Clonar repositorio
git clone https://github.com/tu-usuario/distrisearch.git
cd distrisearch/DistriSearch

# 2. Configurar variables de entorno
cp deploy/.env.example deploy/.env
nano deploy/.env  # Editar configuraci√≥n

# 3. Iniciar sistema completo
cd deploy
docker-compose up -d

# 4. Verificar servicios
docker-compose ps
```

**Servicios levantados:**
- Backend: http://localhost:8000
- Frontend: http://localhost:8501
- MongoDB: localhost:27017
- Agente: http://localhost:8080

### Opci√≥n 2: Manual (Desarrollo)

```bash
# Backend
cd DistriSearch/backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py

# Frontend (otra terminal)
cd DistriSearch/frontend
pip install -r requirements.txt
streamlit run app.py

# Agente (otra terminal)
cd DistriSearch/agent
pip install -r requirements.txt
python agent_dynamic.py
```

---

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

#### Backend (`backend/.env`)

```bash
# MongoDB
MONGO_URI=mongodb://localhost:27017
MONGO_DBNAME=distrisearch
GRIDFS_THRESHOLD_BYTES=200000  # 200 KB

# Servidor
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
NODE_ID=central
EXTERNAL_IP=192.168.1.100  # Tu IP en LAN

# Seguridad
ADMIN_API_KEY=tu_api_key_secreta_aqui
SECRET_KEY=tu_secret_key_jwt_aqui

# SSL (opcional)
ENABLE_SSL=false
SSL_CERT_FILE=../certs/distrisearch.crt
SSL_KEY_FILE=../certs/distrisearch.key

# Replicaci√≥n
REPLICATION_ENABLED=true
REPLICATION_FACTOR=3
CONSISTENCY_MODEL=eventual
CONFLICT_RESOLUTION=last_write_wins
SYNC_INTERVAL_SECONDS=60

# Mantenimiento
MAINTENANCE_INTERVAL_SECONDS=300  # 5 min
NODE_DISCOVERY_INTERVAL=30

# Checkpoints
CHECKPOINT_INTERVAL_SECONDS=300  # 5 min

# Coordinaci√≥n
POW_DIFFICULTY=4  # Dificultad PoW

# Multicast
MULTICAST_GROUP=239.255.0.1
MULTICAST_PORT=5353
DISCOVERY_INTERVAL=30

# Timeouts
NODE_TIMEOUT_MINUTES=5
```

#### Frontend (`frontend/.env`)

```bash
DISTRISEARCH_BACKEND_URL=http://localhost:8000
DISTRISEARCH_BACKEND_PUBLIC_URL=http://192.168.1.100:8000
DISTRISEARCH_ADMIN_API_KEY=tu_api_key_secreta_aqui
```

#### Agente (`agent/.env`)

```bash
NODE_ID=agent_01
BACKEND_URL=http://localhost:8000
ADMIN_API_KEY=tu_api_key_secreta_aqui

FILE_SERVER_PORT=8080
SHARED_FOLDER=./shared
SCAN_INTERVAL=300  # 5 min
```

### Configuraci√≥n de Replicaci√≥n

**Escenarios:**

```bash
# Alta disponibilidad (recomendado)
REPLICATION_FACTOR=3
SYNC_INTERVAL_SECONDS=60
CHECKPOINT_INTERVAL_SECONDS=300

# Ahorro de espacio
REPLICATION_FACTOR=2
SYNC_INTERVAL_SECONDS=120

# M√°xima redundancia
REPLICATION_FACTOR=5
SYNC_INTERVAL_SECONDS=30
CHECKPOINT_INTERVAL_SECONDS=180
```

---

## üìñ Uso

### 1. Subir Archivos

**Desde Frontend:**

1. Acceder a http://localhost:8501
2. Iniciar sesi√≥n (o registrarse)
3. Ir a **"üì§ Subir Archivos"**
4. Seleccionar archivos
5. Elegir nodo destino
6. Hacer clic en **"Subir"**

**Desde API:**

```bash
curl -X POST http://localhost:8000/register/upload \
  -H "X-API-KEY: tu_api_key" \
  -F "file=@documento.pdf" \
  -F "node_id=central"
```

### 2. Buscar Archivos

**Desde Frontend:**

1. Ir a **"üîç Buscar"**
2. Ingresar t√©rminos de b√∫squeda
3. Filtrar por tipo (opcional)
4. Hacer clic en **"Buscar"**

**Desde API:**

```bash
curl "http://localhost:8000/search/?q=documento&file_type=document&max_results=50" \
  -H "Authorization: Bearer tu_token_jwt"
```

**Con BM25 score:**

```bash
curl "http://localhost:8000/search/?q=importante&include_score=true"
```

### 3. Descargar Archivos

**Desde Frontend:**

- Hacer clic en **"üì• Descargar"** en resultados de b√∫squeda

**Desde API:**

```bash
# Obtener URL de descarga
curl -X POST http://localhost:8000/download/ \
  -H "Authorization: Bearer tu_token" \
  -H "Content-Type: application/json" \
  -d '{"file_id": "abc123"}'

# Descarga directa
curl http://localhost:8000/download/file/abc123 -o archivo.pdf
```

### 4. Gestionar Nodos

**Registrar nodo manualmente:**

```bash
curl -X POST http://localhost:8000/register/node \
  -H "X-API-KEY: tu_api_key" \
  -H "Content-Type: application/json" \
  -d '{
    "node_id": "agent_02",
    "name": "Agente 02",
    "ip_address": "192.168.1.101",
    "port": 8080,
    "status": "online"
  }'
```

**Verificar nodos online:**

```bash
curl http://localhost:8000/search/nodes
```

**Eliminar nodo:**

```bash
curl -X DELETE "http://localhost:8000/register/node/agent_02?delete_files=true" \
  -H "X-API-KEY: tu_api_key"
```

### 5. Iniciar Elecci√≥n de L√≠der

```bash
curl -X POST http://localhost:8000/coordination/election/start \
  -H "X-API-KEY: tu_api_key" \
  -d '{"reason": "manual"}'
```

### 6. Crear Checkpoint

```bash
curl -X POST http://localhost:8000/fault_tolerance/checkpoint/create \
  -H "X-API-KEY: tu_api_key"
```

### 7. Ver M√©tricas de Confiabilidad

```bash
# M√©tricas de un nodo
curl http://localhost:8000/fault_tolerance/metrics/node/agent_01

# M√©tricas del sistema
curl http://localhost:8000/fault_tolerance/metrics/system
```

---

## üîå API Endpoints

### Autenticaci√≥n

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/auth/register` | Registrar usuario |
| POST | `/auth/token` | Obtener token JWT |
| GET | `/auth/me` | Obtener usuario actual |

### B√∫squeda

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| GET | `/search/` | Buscar archivos |
| GET | `/search/stats` | Estad√≠sticas del sistema |
| GET | `/search/nodes` | Listar nodos |

### Registro

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/register/node` | Registrar nodo |
| POST | `/register/files` | Registrar archivos |
| POST | `/register/heartbeat/{node_id}` | Heartbeat |
| DELETE | `/register/node/{node_id}` | Eliminar nodo |
| POST | `/register/upload` | Subir archivo |
| POST | `/register/upload/bulk` | Subir m√∫ltiples archivos |

### Descarga

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/download/` | Obtener URL de descarga |
| GET | `/download/file/{file_id}` | Descargar archivo |
| GET | `/download/direct/{file_id}` | Redirecci√≥n directa |

### Coordinaci√≥n

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/coordination/election/start` | Iniciar elecci√≥n |
| POST | `/coordination/election` | Recibir notificaci√≥n de elecci√≥n |
| POST | `/coordination/leader` | Recibir anuncio de l√≠der |
| GET | `/coordination/status` | Estado de coordinaci√≥n |
| POST | `/coordination/lock/acquire` | Adquirir mutex |
| POST | `/coordination/lock/release` | Liberar mutex |

### Naming

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/naming/register_path` | Registrar path jer√°rquico |
| GET | `/naming/resolve` | Resolver path a archivo |
| GET | `/naming/list` | Listar directorio |
| POST | `/naming/alias` | Crear alias |
| GET | `/naming/search` | Buscar por patr√≥n |
| GET | `/naming/tree` | Obtener estructura de √°rbol |

### Tolerancia a Fallos

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/fault_tolerance/checkpoint/create` | Crear checkpoint |
| POST | `/fault_tolerance/checkpoint/restore/{id}` | Restaurar checkpoint |
| GET | `/fault_tolerance/metrics/node/{id}` | M√©tricas de nodo |
| GET | `/fault_tolerance/metrics/system` | M√©tricas del sistema |
| GET | `/fault_tolerance/replication/status` | Estado de replicaci√≥n |

---

## üìä M√©tricas y Monitoreo

### Dashboard de Estad√≠sticas

**Frontend ‚Üí Pesta√±a "üìä Estad√≠sticas"**

Muestra:
- Total de archivos
- Nodos online/offline
- Distribuci√≥n por tipo de archivo
- Indicador de salud del sistema (gauge)
- Gr√°ficos interactivos con Plotly

### M√©tricas de Confiabilidad

**Endpoint:** `GET /fault_tolerance/metrics/node/{node_id}`

**Respuesta:**

```json
{
  "node_id": "agent_01",
  "mttf": 86400.0,
  "mttr": 120.0,
  "mtbf": 86520.0,
  "availability": 0.9986,
  "failures_count": 3,
  "window_days": 30,
  "calculated_at": "2024-01-15T10:00:00Z"
}
```

**Interpretaci√≥n:**

- **MTTF = 86400s (24h)**: El nodo funciona 24h en promedio antes de fallar
- **MTTR = 120s (2 min)**: La recuperaci√≥n toma 2 minutos
- **Disponibilidad = 99.86%**: El nodo est√° online el 99.86% del tiempo

### Logs Estructurados

**Configuraci√≥n de logging:**

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('distrisearch.log'),
        logging.StreamHandler()
    ]
)
```

**Eventos importantes:**

```
‚úÖ Nodo registrado: agent_01 (192.168.1.100:8080)
üîÑ Iniciando replicaci√≥n de archivo abc123 a 3 nodos
‚úÖ Archivo abc123 replicado a agent_01
‚ö†Ô∏è Detectados 1 nodos ca√≠dos - Iniciando recuperaci√≥n
üìä Recuperaci√≥n de agent_02: recovered=15, failed=0
üëë Nuevo l√≠der elegido: agent_01 (T√©rmino: 5)
‚úÖ Checkpoint coordinado creado: checkpoint_xyz
```

---

## üß™ Testing

### Tests Unitarios

```bash
cd DistriSearch/backend

# Ejecutar todos los tests
pytest

# Tests espec√≠ficos
pytest tests/test_search.py
pytest tests/test_register.py
pytest tests/test_download.py
```

### Tests de Integraci√≥n

```bash
# Test end-to-end
pytest test/test_end_to_end.py -v

# Test de robustez (tolerancia a fallos)
pytest test/test_fault_tolerance.py -v

# Test de consistencia de replicaci√≥n
pytest test/test_replication_consistency.py -v
```

### Escenarios de Prueba

#### 1. Tolerancia a Fallos

```bash
# Iniciar sistema con 3 nodos
docker-compose up -d

# Simular ca√≠da de nodo
docker-compose stop agent

# Verificar que el sistema sigue funcionando
curl http://localhost:8000/search/stats

# Esperar recuperaci√≥n autom√°tica (5 min)
# Verificar que archivos se replicaron
curl http://localhost:8000/fault_tolerance/replication/status
```

#### 2. Replicaci√≥n Din√°mica

```bash
# Subir archivo
curl -X POST http://localhost:8000/register/upload \
  -H "X-API-KEY: test_key" \
  -F "file=@test.pdf"

# Verificar que se replic√≥ a k=3 nodos
curl http://localhost:8000/search/?q=test.pdf | jq '.nodes_available | length'
# Deber√≠a devolver 3
```

#### 3. Elecci√≥n de L√≠der

```bash
# Forzar nueva elecci√≥n
curl -X POST http://localhost:8000/coordination/election/start \
  -H "X-API-KEY: test_key"

# Verificar l√≠der elegido
curl http://localhost:8000/coordination/status | jq '.current_leader'
```

---

## üîß Troubleshooting

### Problemas Comunes

#### 1. MongoDB Connection Error

**S√≠ntoma:**

```
‚ùå Error conectando a MongoDB: ServerSelectionTimeoutError
```

**Soluci√≥n:**

```bash
# Verificar que MongoDB est√° corriendo
docker ps | grep mongo

# Si no est√°, iniciarlo
docker-compose up -d mongo

# Verificar logs
docker-compose logs mongo
```

#### 2. Nodo no se auto-registra

**S√≠ntoma:** Agente no aparece en lista de nodos

**Soluci√≥n:**

```bash
# Verificar que el agente puede conectar al backend
docker-compose logs agent | grep "Registrado exitosamente"

# Verificar variables de entorno
docker-compose exec agent env | grep BACKEND_URL

# Registro manual
curl -X POST http://localhost:8000/register/node/dynamic \
  -H "Content-Type: application/json" \
  -d '{
    "node_id": "agent_01",
    "port": 8080,
    "auto_scan": true
  }'
```

#### 3. Replicaci√≥n no funciona

**S√≠ntoma:** Archivos no se replican a k nodos

**Diagn√≥stico:**

```bash
# Verificar configuraci√≥n
curl http://localhost:8000/fault_tolerance/replication/status

# Verificar nodos online
curl http://localhost:8000/search/nodes | jq '.[] | select(.status=="online")'

# Ver logs de replicaci√≥n
docker-compose logs backend | grep "Replicaci√≥n"
```

**Soluci√≥n:**

```bash
# Asegurar al menos k nodos online
docker-compose up -d --scale agent=3

# Forzar sincronizaci√≥n
curl -X POST http://localhost:8000/fault_tolerance/checkpoint/create
```

#### 4. B√∫squeda no encuentra archivos

**S√≠ntoma:** Query retorna 0 resultados

**Diagn√≥stico:**

```bash
# Verificar que archivos est√°n indexados
mongo distrisearch --eval "db.files.countDocuments({})"

# Verificar √≠ndice full-text
mongo distrisearch --eval "db.file_contents.getIndexes()"
```

**Soluci√≥n:**

```bash
# Re-indexar archivos
curl -X POST http://localhost:8000/register/node/{node_id}/sync \
  -H "X-API-KEY: test_key"
```

#### 5. Multicast discovery no funciona

**S√≠ntoma:** Nodos no se descubren autom√°ticamente

**Soluci√≥n:**

```bash
# Verificar firewall permite UDP multicast
sudo ufw allow 5353/udp

# Windows: Permitir en firewall
netsh advfirewall firewall add rule name="DistriSearch Multicast" dir=in action=allow protocol=UDP localport=5353

# Verificar que red Docker permite multicast
docker network inspect distrisearch_network | jq '.[0].Options'
```

### Logs de Debugging

```bash
# Backend
docker-compose logs -f backend

# Agente
docker-compose logs -f agent

# MongoDB
docker-compose logs -f mongo

# Todos
docker-compose logs -f
```

---

## ü§ù Contribuci√≥n

### Gu√≠a de Contribuci√≥n

1. **Fork** el repositorio
2. **Crear** rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. **Push** a rama (`git push origin feature/nueva-funcionalidad`)
5. **Crear** Pull Request

### Est√°ndares de C√≥digo

```bash
# Formatear c√≥digo
black backend/ frontend/ agent/

# Linting
flake8 backend/ --max-line-length=120

# Type checking
mypy backend/
```

### Checklist de PR

- [ ] Tests pasan (`pytest`)
- [ ] C√≥digo formateado (`black`)
- [ ] Documentaci√≥n actualizada
- [ ] Changelog actualizado
- [ ] Sin warnings de linting

---

## üìÑ Licencia

MIT License - Ver [LICENSE](LICENSE) para m√°s detalles

---

## üë• Autores

- **Tu Nombre** - *Desarrollo Principal* - [GitHub](https://github.com/tu-usuario)

---

## üôè Agradecimientos

- **Andrew Tanenbaum** - "Distributed Systems: Principles and Paradigms" (teor√≠a base)
- **MongoDB** - Base de datos NoSQL escalable
- **FastAPI** - Framework web moderno
- **Streamlit** - Framework de frontend r√°pido

---

## üìû Soporte

- **Documentaci√≥n completa**: [docs/index.md](docs/index.md)
- **Issues**: https://github.com/tu-usuario/distrisearch/issues
- **Email**: soporte@distrisearch.com

---

## üó∫Ô∏è Roadmap

### v2.1.0 (Q2 2024)

- [ ] Mejoras en el balanceo de carga del Master
- [ ] Algoritmo de consenso Raft como alternativa a Bully
- [ ] Replicaci√≥n geogr√°fica con awareness de latencia
- [ ] Compresi√≥n de archivos en tr√°nsito
- [ ] Deduplicaci√≥n a nivel de bloque

### v2.2.0 (Q3 2024)

- [ ] WebRTC para transferencias P2P directas
- [ ] Cifrado end-to-end opcional
- [ ] Cliente m√≥vil (Android/iOS)
- [ ] Plugin para integraciones (Google Drive, Dropbox)
- [ ] Machine Learning para relevancia de b√∫squeda

### v3.0.0 (Q4 2024)

- [ ] Blockchain para audit trail inmutable
- [ ] IPFS integration
- [ ] GraphQL API
- [ ] Multi-tenancy
- [ ] Kubernetes Operator

---

## üìä Estad√≠sticas del Proyecto

```
Backend:
  - Lines of Code: ~5,000
  - Files: 25
  - Tests: 50+
  - Coverage: 85%

Frontend:
  - Components: 15
  - Pages: 4
  - UI Framework: Streamlit

Database:
  - Collections: 12
  - Indexes: 20+
  - Estimated Scale: 100K+ files
```

---

## üéì Referencias Acad√©micas

1. Tanenbaum, A. S., & Van Steen, M. (2017). *Distributed systems: principles and paradigms*. Prentice-Hall.

2. Lamport, L. (1978). *Time, clocks, and the ordering of events in a distributed system*. Communications of the ACM, 21(7), 558-565.

3. Ricart, G., & Agrawala, A. K. (1981). *An optimal algorithm for mutual exclusion in computer networks*. Communications of the ACM, 24(1), 9-17.

4. Nakamoto, S. (2008). *Bitcoin: A peer-to-peer electronic cash system*.

5. Brewer, E. A. (2000). *Towards robust distributed systems*. PODC.

---

## üèÜ Features Destacadas

### ‚ú® Lo que hace √∫nico a DistriSearch:

1. **Verdadera Arquitectura P2P**: No hay servidor central, cualquier nodo puede ser l√≠der
2. **Tolerancia a Fallos Certificada**: Basado en teor√≠a acad√©mica probada
3. **Replicaci√≥n Inteligente**: Hash consistente para distribuci√≥n uniforme
4. **Consistencia Eventual**: Sincronizaci√≥n autom√°tica cada 60 segundos
5. **Zero-Configuration**: Nodos se autodescubren en LAN
6. **M√©tricas Acad√©micas**: MTTF, MTTR, MTBF tracking real
7. **Checkpoints Coordinados**: Snapshots consistentes del sistema completo
8. **Naming Jer√°rquico**: Organizaci√≥n estilo Unix filesystem

---

**¬øListo para distribuir tu b√∫squeda? üöÄ**

```bash
git clone https://github.com/tu-usuario/distrisearch.git
cd distrisearch/DistriSearch/deploy
docker-compose up -d
```

**¬°Disfruta de DistriSearch!** üîç‚ú®