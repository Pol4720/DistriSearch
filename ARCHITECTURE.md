# Arquitectura de DistriSearch

## ğŸ“ VisiÃ³n General

DistriSearch es un buscador distribuido que combina:
- TopologÃ­a de **hipercubo lÃ³gico** para organizaciÃ³n de nodos
- **Data Balancer replicado** para coordinar metadatos de tÃ©rminos
- **ElecciÃ³n de lÃ­der** automÃ¡tica (algoritmo Bully)
- **Ãndices invertidos locales** en cada nodo
- **Ruteo XOR-based** para comunicaciÃ³n entre nodos

## ğŸ—ï¸ Componentes Principales

### 1. Nodo Distribuido (`node.py`)

Cada nodo es autÃ³nomo y contiene:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Nodo Distribuido                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   API HTTP (aiohttp)            â”‚   â”‚
â”‚  â”‚   - POST /doc                   â”‚   â”‚
â”‚  â”‚   - GET /search                 â”‚   â”‚
â”‚  â”‚   - POST /route                 â”‚   â”‚
â”‚  â”‚   - GET /status                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Ãndice Invertido Local        â”‚   â”‚
â”‚  â”‚   tÃ©rmino â†’ {doc_id: score}     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   MÃ³dulo de Hipercubo           â”‚   â”‚
â”‚  â”‚   - ID binario                  â”‚   â”‚
â”‚  â”‚   - Lista de vecinos            â”‚   â”‚
â”‚  â”‚   - Ruteo XOR                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   ElecciÃ³n de LÃ­der (Bully)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Data Balancer (si es lÃ­der)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. TopologÃ­a Hipercubo (`hypercube.py`)

El hipercubo organiza nodos en un espacio lÃ³gico d-dimensional:

```
Ejemplo: Hipercubo de 3 bits (8 nodos posibles)

        001 â”€â”€â”€â”€â”€â”€â”€ 101
       /â”‚          /â”‚
      / â”‚         / â”‚
    000â”€â”¼â”€â”€â”€â”€â”€â”€â”€100 â”‚
     â”‚  011 â”€â”€â”€â”€â”€â”¼â”€111
     â”‚ /         â”‚ /
     â”‚/          â”‚/
    010 â”€â”€â”€â”€â”€â”€â”€ 110

Vecinos del nodo 000:
- Bit 0: 001 (flip bit 0)
- Bit 1: 010 (flip bit 1)
- Bit 2: 100 (flip bit 2)
```

**Algoritmo de Ruteo:**
1. Calcular XOR entre nodo actual y destino
2. Elegir bit mÃ¡s significativo diferente
3. Si el vecino existe, enviar mensaje
4. Si no, usar greedy: elegir vecino que minimice distancia XOR

### 3. Ãndice Invertido (`storage.py`)

Estructura de datos local en cada nodo:

```
Ãndice Invertido:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TÃ©rmino  â”‚ Postings           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ python   â”‚ {doc1: 3.0,        â”‚
â”‚          â”‚  doc3: 1.0}        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ java     â”‚ {doc2: 2.0}        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Documentos:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Doc ID â”‚ Contenido               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ doc1   â”‚ "Python programming..." â”‚
â”‚ doc2   â”‚ "Java development..."   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Data Balancer (`databalancer.py`)

Mantiene Ã­ndice global de tÃ©rminos:

```
Ãndice Global (en lÃ­der):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TÃ©rmino  â”‚ Nodos que lo tienen â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ python   â”‚ {0, 2, 4}           â”‚
â”‚ java     â”‚ {1, 3}              â”‚
â”‚ docker   â”‚ {0, 1, 2}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Metadatos de Nodos:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node ID â”‚ Endpoint â”‚ Ãšltima HB    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0       â”‚ :8000    â”‚ 1234567890.1 â”‚
â”‚ 1       â”‚ :8001    â”‚ 1234567889.5 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. ElecciÃ³n de LÃ­der (`election.py`)

Algoritmo Bully adaptado:

```
Escenario: Nodo 3 detecta fallo del lÃ­der (nodo 7)

Paso 1: Nodo 3 envÃ­a ELECTION a nodos con ID mayor
        3 â†’ ELECTION â†’ [4, 5, 6, 7]

Paso 2: Nodos vivos responden OK
        4 â†’ OK â†’ 3
        5 â†’ OK â†’ 3
        (6 y 7 no responden)

Paso 3: Nodo 3 espera que ellos se encarguen
        
Paso 4: Nodo 5 (mayor ID vivo) envÃ­a ELECTION a [6, 7]
        No recibe OK (timeout)

Paso 5: Nodo 5 se declara COORDINATOR
        5 â†’ COORDINATOR â†’ [todos]

Resultado: Nodo 5 es el nuevo lÃ­der
```

## ğŸ”„ Flujos de OperaciÃ³n

### Flujo 1: Indexar Documento

```
1. Cliente â†’ POST /doc â†’ Nodo A
2. Nodo A: Tokeniza y aÃ±ade a Ã­ndice local
3. Nodo A: Guarda en disco
4. Nodo A â†’ POST /update_index â†’ LÃ­der
   {node_id: A, terms_added: ["python", "java"]}
5. LÃ­der: Actualiza Ã­ndice global
   python â†’ {A, ...}
   java â†’ {A, ...}
6. LÃ­der: Responde OK
7. Nodo A â†’ Cliente: {status: ok}
```

### Flujo 2: BÃºsqueda Distribuida

```
1. Cliente â†’ GET /search?q=python â†’ Nodo A

2. Nodo A: Tokeniza "python" â†’ ["python"]

3. Para cada tÃ©rmino:
   Nodo A â†’ GET /locate?q=python â†’ LÃ­der
   
4. LÃ­der responde:
   {term: "python", nodes: [{node_id: 0, ...}, {node_id: 2, ...}]}

5. Nodo A consulta a cada nodo candidato:
   Nodo A â†’ mensaje search_local â†’ Nodo 0 (vÃ­a ruteo)
   Nodo A â†’ mensaje search_local â†’ Nodo 2 (vÃ­a ruteo)

6. Cada nodo responde con resultados locales:
   Nodo 0 â†’ {results: [{doc1, score: 3.0}, ...]}
   Nodo 2 â†’ {results: [{doc5, score: 1.5}, ...]}

7. Nodo A agrega y ordena:
   [doc1 (3.0), doc5 (1.5), ...]

8. Nodo A â†’ Cliente: {query: "python", results: [...]}
```

### Flujo 3: Ruteo de Mensaje

```
Objetivo: Nodo 2 (010) quiere enviar a Nodo 7 (111)

Paso 1: Calcular XOR
  2 XOR 7 = 010 XOR 111 = 101
  Bits diferentes: 0, 2

Paso 2: Elegir bit mÃ¡s significativo (bit 2)
  Vecino candidato: 010 XOR 100 = 110 (Nodo 6)

Paso 3: Â¿Nodo 6 estÃ¡ disponible?
  SÃ â†’ Enviar a Nodo 6
  NO â†’ Usar greedy: buscar vecino con menor XOR a destino

Paso 4: Nodo 6 recibe y reenvÃ­a
  6 (110) a 7 (111)
  XOR = 001, bit 0 diferente
  Vecino: 110 XOR 001 = 111 (Nodo 7)
  
Paso 5: Nodo 7 recibe mensaje (destino alcanzado)

Ruta total: 2 â†’ 6 â†’ 7 (2 saltos)
```

## ğŸ“Š Modelo de Datos

### Documento
```python
{
    "doc_id": "unique_id",
    "content": "texto del documento",
    "metadata": {
        "author": "usuario",
        "timestamp": 1234567890
    }
}
```

### Mensaje de Ruteo
```python
{
    "type": "route",
    "dest_id": 7,
    "hop_limit": 32,
    "payload": {
        "type": "ping",
        "sender_id": 2
    }
}
```

### ActualizaciÃ³n de Ãndice
```python
{
    "node_id": 3,
    "terms_added": ["python", "docker"],
    "terms_removed": ["java"],
    "timestamp": 1234567890.5
}
```

## ğŸ¯ Decisiones de DiseÃ±o

### Â¿Por quÃ© NO DHT?

- **Control centralizado (replicado)**: Data Balancer mantiene vista completa
- **Simplicidad**: MÃ¡s fÃ¡cil de entender y debuguear
- **Flexibilidad**: PolÃ­ticas de replicaciÃ³n/balanceo personalizables
- **Trade-off**: Punto de fallo (mitigado por elecciÃ³n de lÃ­der)

### Â¿Por quÃ© Bully y no Raft?

- **Simplicidad**: Bully es mÃ¡s fÃ¡cil de implementar
- **Suficiente para prototipo**: Demo funcional de elecciÃ³n
- **LimitaciÃ³n conocida**: No garantiza fuerte consistencia
- **Mejora futura**: Reemplazar por Raft para producciÃ³n

### Â¿Por quÃ© Hipercubo?

- **Ruteo predecible**: O(log N) saltos mÃ¡ximo
- **Tolerancia a fallos**: MÃºltiples rutas alternativas
- **Escalabilidad**: Crecimiento exponencial
- **Eficiencia**: Bajo overhead de mantenimiento

## ğŸ” GarantÃ­as y Limitaciones

### GarantÃ­as âœ…
- Eventual consistency del Ã­ndice global
- ElecciÃ³n de lÃ­der eventual
- Ruteo always-forward (reduce distancia XOR)
- Datos locales siempre accesibles

### Limitaciones âš ï¸
- No hay strong consistency
- PÃ©rdida de datos si nodo falla (no replicados)
- LÃ­der Ãºnico es bottleneck
- Network partitions no manejadas explÃ­citamente

## ğŸ“ˆ Complejidad

| OperaciÃ³n              | Complejidad      | Notas                    |
|------------------------|------------------|--------------------------|
| Ruteo                  | O(d)             | d = dimensiones          |
| BÃºsqueda local         | O(log D)         | D = docs locales         |
| BÃºsqueda distribuida   | O(d + kÂ·log D)   | k = nodos consultados    |
| ElecciÃ³n lÃ­der         | O(nÂ²)            | n = nodos totales        |
| Update Ã­ndice          | O(t)             | t = tÃ©rminos nuevos      |

## ğŸš€ Extensiones Posibles

1. **ReplicaciÃ³n de datos**: Cada doc en k nodos
2. **Sharding del Data Balancer**: Particionar Ã­ndice global
3. **Caching distribuido**: LRU cache en cada nodo
4. **CompresiÃ³n**: CompresiÃ³n de Ã­ndices y documentos
5. **Ranking avanzado**: TF-IDF, BM25, word2vec
6. **Geo-awareness**: Ruteo consciente de latencia
7. **Multi-tenancy**: Aislamiento por namespace

---

**Nota**: Esta arquitectura prioriza simplicidad y educaciÃ³n sobre optimizaciÃ³n extrema.
