#!/usr/bin/env python3
"""
DNS Zone Sync Daemon for DistriSearch

This daemon monitors Docker Swarm services and automatically updates
CoreDNS zone files when services are added, removed, or their IPs change.

The sync process runs every SYNC_INTERVAL seconds (default: 30).
"""

import os
import sys
import time
import socket
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple

try:
    import docker
except ImportError:
    print("ERROR: docker package not installed. Run: pip install docker")
    sys.exit(1)

# Configuration from environment
SYNC_INTERVAL = int(os.environ.get('SYNC_INTERVAL', 30))
COREDNS_ZONE_PATH = os.environ.get('COREDNS_ZONE_PATH', '/zones')
ZONE_FILE = os.path.join(COREDNS_ZONE_PATH, 'distrisearch.local.zone')
DOCKER_HOST = os.environ.get('DOCKER_HOST', 'unix:///var/run/docker.sock')

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# Services we care about
TRACKED_SERVICES = ['master', 'slave', 'mongodb', 'redis', 'coredns', 'load-balancer']


def get_docker_client() -> docker.DockerClient:
    """Create Docker client connection."""
    try:
        client = docker.DockerClient(base_url=DOCKER_HOST)
        client.ping()
        logger.info("Connected to Docker daemon")
        return client
    except Exception as e:
        logger.error(f"Failed to connect to Docker: {e}")
        raise


def get_service_ips(client: docker.DockerClient) -> Dict[str, List[str]]:
    """
    Get IP addresses for all tracked services.
    
    Returns:
        Dict mapping service name to list of IP addresses
    """
    service_ips: Dict[str, List[str]] = {}
    
    try:
        # Get all services in the swarm
        services = client.services.list()
        
        for service in services:
            service_name = service.name
            
            # Check if this is a tracked service
            base_name = service_name.split('_')[-1] if '_' in service_name else service_name
            if not any(tracked in base_name.lower() for tracked in TRACKED_SERVICES):
                continue
            
            ips = []
            
            # Get tasks (running instances) for this service
            tasks = service.tasks(filters={'desired-state': 'running'})
            
            for task in tasks:
                task_state = task.get('Status', {}).get('State', '')
                if task_state != 'running':
                    continue
                
                # Get network attachments
                networks = task.get('NetworksAttachments', [])
                for network in networks:
                    addresses = network.get('Addresses', [])
                    for addr in addresses:
                        # Extract IP from CIDR notation (e.g., "10.0.10.5/24")
                        ip = addr.split('/')[0]
                        if ip and not ip.startswith('127.'):
                            ips.append(ip)
            
            if ips:
                service_ips[base_name] = ips
                logger.debug(f"Service {base_name}: {ips}")
    
    except Exception as e:
        logger.error(f"Error getting service IPs: {e}")
    
    return service_ips


def generate_zone_file(service_ips: Dict[str, List[str]]) -> str:
    """
    Generate zone file content from service IPs.
    
    Args:
        service_ips: Dict mapping service name to list of IP addresses
        
    Returns:
        Zone file content as string
    """
    serial = datetime.now().strftime('%Y%m%d%H')
    
    zone_content = f"""; ═══════════════════════════════════════════════════════════════════════════
; DistriSearch Zone File
; Auto-generated by dns-sync daemon at {datetime.now().isoformat()}
; DO NOT EDIT MANUALLY - changes will be overwritten
; ═══════════════════════════════════════════════════════════════════════════

$ORIGIN distrisearch.local.
$TTL 30

@       IN      SOA     ns1.distrisearch.local. admin.distrisearch.local. (
                        {serial}        ; Serial (auto-generated)
                        3600            ; Refresh (1 hour)
                        600             ; Retry (10 minutes)
                        86400           ; Expire (1 day)
                        30              ; Minimum TTL
                        )

; Name servers
@       IN      NS      ns1.distrisearch.local.
ns1     IN      A       127.0.0.1

; ═══════════════════════════════════════════════════════════════════════════
; SERVICE RECORDS (auto-updated)
; ═══════════════════════════════════════════════════════════════════════════

"""
    
    # Add A records for each service
    for service_name, ips in sorted(service_ips.items()):
        zone_content += f"; {service_name} service\n"
        
        # Add main service name pointing to all IPs (round-robin)
        for ip in ips:
            zone_content += f"{service_name.ljust(15)} IN      A       {ip}\n"
        
        # Add numbered instances
        for i, ip in enumerate(ips, 1):
            zone_content += f"{f'{service_name}-{i}'.ljust(15)} IN      A       {ip}\n"
        
        zone_content += "\n"
    
    # Add CNAME records
    zone_content += """; ═══════════════════════════════════════════════════════════════════════════
; CNAME RECORDS
; ═══════════════════════════════════════════════════════════════════════════

www             IN      CNAME   slave.distrisearch.local.
api             IN      CNAME   slave.distrisearch.local.
db              IN      CNAME   mongodb.distrisearch.local.
cache           IN      CNAME   redis.distrisearch.local.

"""
    
    # Add SRV records
    zone_content += """; ═══════════════════════════════════════════════════════════════════════════
; SRV RECORDS
; ═══════════════════════════════════════════════════════════════════════════

_master._tcp    IN      SRV     10 50 8001 master.distrisearch.local.
_api._tcp       IN      SRV     10 50 8000 slave.distrisearch.local.
_mongodb._tcp   IN      SRV     10 50 27017 mongodb.distrisearch.local.
_redis._tcp     IN      SRV     10 50 6379 redis.distrisearch.local.
"""
    
    return zone_content


def update_zone_file(content: str) -> bool:
    """
    Write zone file content to disk.
    
    Args:
        content: Zone file content
        
    Returns:
        True if file was updated, False otherwise
    """
    try:
        # Read existing content
        existing_content = ""
        if os.path.exists(ZONE_FILE):
            with open(ZONE_FILE, 'r') as f:
                existing_content = f.read()
        
        # Compare (ignoring serial number and timestamp)
        def normalize(s):
            lines = s.split('\n')
            return [l for l in lines if not l.strip().startswith(';') and 'Serial' not in l]
        
        if normalize(content) == normalize(existing_content):
            logger.debug("Zone file unchanged, skipping update")
            return False
        
        # Ensure directory exists
        os.makedirs(os.path.dirname(ZONE_FILE), exist_ok=True)
        
        # Write new content
        with open(ZONE_FILE, 'w') as f:
            f.write(content)
        
        logger.info(f"Updated zone file: {ZONE_FILE}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to update zone file: {e}")
        return False


def reload_coredns():
    """
    Signal CoreDNS to reload zone files.
    
    CoreDNS automatically watches zone files for changes,
    but we can also try to send a signal if needed.
    """
    try:
        # CoreDNS auto-reloads when files change, so this is mostly a no-op
        # If manual reload is needed, we could use the reload plugin API
        logger.debug("CoreDNS will auto-reload zone file")
    except Exception as e:
        logger.warning(f"Could not signal CoreDNS reload: {e}")


def main():
    """Main sync loop."""
    logger.info("=" * 60)
    logger.info("DistriSearch DNS Sync Daemon Starting")
    logger.info(f"Sync interval: {SYNC_INTERVAL}s")
    logger.info(f"Zone file path: {ZONE_FILE}")
    logger.info("=" * 60)
    
    client = None
    consecutive_errors = 0
    max_consecutive_errors = 5
    
    while True:
        try:
            # Connect to Docker if needed
            if client is None:
                client = get_docker_client()
            
            # Get current service IPs
            service_ips = get_service_ips(client)
            
            if service_ips:
                logger.info(f"Found {len(service_ips)} services: {list(service_ips.keys())}")
                
                # Generate and update zone file
                zone_content = generate_zone_file(service_ips)
                if update_zone_file(zone_content):
                    reload_coredns()
            else:
                logger.warning("No services found, keeping existing zone file")
            
            consecutive_errors = 0
            
        except docker.errors.APIError as e:
            consecutive_errors += 1
            logger.error(f"Docker API error: {e}")
            client = None  # Force reconnect
            
        except Exception as e:
            consecutive_errors += 1
            logger.error(f"Sync error: {e}")
        
        if consecutive_errors >= max_consecutive_errors:
            logger.critical(f"Too many consecutive errors ({consecutive_errors}), exiting")
            sys.exit(1)
        
        # Wait for next sync interval
        logger.debug(f"Sleeping for {SYNC_INTERVAL}s...")
        time.sleep(SYNC_INTERVAL)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logger.info("Shutting down DNS sync daemon")
        sys.exit(0)
