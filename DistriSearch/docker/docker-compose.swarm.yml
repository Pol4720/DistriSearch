# Docker Stack for Docker Swarm Production Deployment
# Deploy with: docker stack deploy -c docker-compose.swarm.yml distrisearch
#
# ARQUITECTURA DINÁMICA: Este compose está diseñado para funcionar con
# cualquier número de nodos. Los servicios escalan automáticamente según
# la cantidad de nodos disponibles en el Swarm.
#
# Imágenes requeridas (locales):
#   - distrisearch/load-balancer:latest
#   - distrisearch/master:latest
#   - distrisearch/slave:latest
#   - distrisearch/coredns:latest
#   - distrisearch/dns-sync:latest
#   - mongo:7.0
#   - redis:7-alpine

version: '3.8'

networks:
  distrisearch-network:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.10.0/24

  ingress-network:
    driver: overlay
    attachable: true

volumes:
  mongodb-data:
    driver: local
  redis-data:
    driver: local
  slave-data:
    driver: local

configs:
  nginx-config:
    file: ./load-balancer/nginx.conf
  coredns-config:
    file: ./coredns/Corefile

secrets:
  mongodb-password:
    external: true
  jwt-secret:
    external: true
  tls-cert:
    external: true
  tls-key:
    external: true
  mongodb-keyfile:
    external: true 

services:
  # ═══════════════════════════════════════════════════════════════════════
  # LOAD BALANCER (Nginx)
  # Desplegado en TODOS los managers para alta disponibilidad
  # ═══════════════════════════════════════════════════════════════════════
  load-balancer:
    image: distrisearch/load-balancer:latest
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: ingress
      - target: 443
        published: 443
        protocol: tcp
        mode: ingress
    networks:
      - distrisearch-network
      - ingress-network
    configs:
      - source: nginx-config
        target: /etc/nginx/nginx.conf
    secrets:
      - tls-cert
      - tls-key
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      rollback_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ═══════════════════════════════════════════════════════════════════════
  # MASTER NODE (Raft Consensus Leader)
  # Se despliega UNA instancia en cada nodo manager disponible (modo global)
  # Esto permite consenso Raft con N managers (mínimo 1, ideal 3+)
  # ═══════════════════════════════════════════════════════════════════════
  master:
    image: distrisearch/master:latest
    environment:
      - NODE_ROLE=master
      - MONGODB_URI=mongodb://mongodb:27017/distrisearch
      - REDIS_URL=redis://redis:6379
      - RAFT_ELECTION_TIMEOUT_MIN=150
      - RAFT_ELECTION_TIMEOUT_MAX=300
      - RAFT_HEARTBEAT_INTERVAL=50
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    networks:
      - distrisearch-network
    secrets:
      - mongodb-password
      - jwt-secret
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      endpoint_mode: dnsrr
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: stop-first
      rollback_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 5
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # ═══════════════════════════════════════════════════════════════════════
  # SLAVE NODES (Frontend + Backend)
  # Se despliega UNA instancia en CADA nodo del Swarm (modo global)
  # Esto permite escalar automáticamente al agregar nodos
  # ═══════════════════════════════════════════════════════════════════════
  slave:
    image: distrisearch/slave:latest
    environment:
      - NODE_ROLE=slave
      - MASTER_SERVICE=master
      - MASTER_PORT=8001
      - MONGODB_URI=mongodb://mongodb:27017/distrisearch
      - REDIS_URL=redis://redis:6379
      - REPLICATION_FACTOR=2
      - DNS_FALLBACK_ENABLED=true
      - COREDNS_HOST=coredns
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
    networks:
      - distrisearch-network
    secrets:
      - mongodb-password
      - jwt-secret
    volumes:
      - type: volume
        source: slave-data
        target: /app/data
    deploy:
      mode: global
      endpoint_mode: vip
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 5
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ═══════════════════════════════════════════════════════════════════════
  # MONGODB REPLICA SET
  # Se despliega en cada manager disponible para formar el replica set
  # Con 1 manager: standalone, con 3+: replica set completo
  # Nota: Usando mongo:4.4 para compatibilidad con CPUs sin AVX
  # ═══════════════════════════════════════════════════════════════════════
  mongodb:
    image: mongo:4.4
    command: ["--replSet", "rs0", "--bind_ip_all"]
    environment:
      - MONGO_INITDB_DATABASE=distrisearch
    networks:
      - distrisearch-network
    secrets:
      - mongodb-password
    volumes:
      - mongodb-data:/data/db
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager
      endpoint_mode: dnsrr
      update_config:
        parallelism: 1
        delay: 60s
        failure_action: rollback
        order: stop-first
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ═══════════════════════════════════════════════════════════════════════
  # REDIS CACHE
  # Servicio singleton en un manager (cache centralizado)
  # ═══════════════════════════════════════════════════════════════════════
  redis:
    image: redis:7-alpine
    command: ["redis-server", "--appendonly", "yes"]
    networks:
      - distrisearch-network
    volumes:
      - redis-data:/data
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ═══════════════════════════════════════════════════════════════════════
  # COREDNS BACKUP DNS SERVER
  # Desplegado en todos los nodos para resolución DNS local
  # ═══════════════════════════════════════════════════════════════════════
  coredns:
    image: distrisearch/coredns:latest
    networks:
      - distrisearch-network
    configs:
      - source: coredns-config
        target: /etc/coredns/Corefile
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    healthcheck:
      test: ["CMD", "dig", "@localhost", "distrisearch.local", "+short"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ═══════════════════════════════════════════════════════════════════════
  # DNS SYNC DAEMON
  # ═══════════════════════════════════════════════════════════════════════
  dns-sync:
    image: distrisearch/dns-sync:latest
    environment:
      - SYNC_INTERVAL=30
      - COREDNS_ZONE_PATH=/zones
      - DOCKER_HOST=unix:///var/run/docker.sock
    networks:
      - distrisearch-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
        reservations:
          cpus: '0.05'
          memory: 32M

# Additional volumes defined inline above
